{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "66d0d3eda91e5879646b3ba1e7491bbb0b49271b31f0264f8c78d03d4ceed0f8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_cf_problem_page(problem_url):\n",
    "    problem_html = requests.get(problem_url)\n",
    "    problem_parse = BeautifulSoup(problem_html.content,\"html.parser\",from_encoding=\"utf-8\")\n",
    "    problem_div = problem_parse.find_all(\"div\")\n",
    "    #問題文の抽出,コドフォのページのhtmlをよく見て該当部分の属性で抽出\n",
    "    res={\"problem_text\":[],\"input_text\":[],\"output_text\":[],\"tags\":[]}\n",
    "    for elem in problem_div:\n",
    "        try:\n",
    "            elem_cls = elem.get(\"class\")[0]\n",
    "            if(elem_cls == \"input-specification\"):\n",
    "                res[\"input_text\"].extend([paragraph.string for paragraph in elem.find_all(\"p\") if paragraph.string is not None])\n",
    "            if(elem_cls == \"output-specification\"):\n",
    "                res[\"output_text\"].extend([paragraph.string for paragraph in elem.find_all(\"p\") if paragraph.string is not None])\n",
    "                break\n",
    "        except:\n",
    "            if(not res[\"problem_text\"]):\n",
    "                res[\"problem_text\"].extend([paragraph.string for paragraph in elem.find_all(\"p\") if paragraph.string is not None])\n",
    "\n",
    "    res[\"problem_text\"]=\"\".join(res[\"problem_text\"])\n",
    "    res[\"input_text\"]=\"\".join(res[\"input_text\"])\n",
    "    res[\"output_text\"]=\"\".join(res[\"output_text\"])\n",
    "    #タグの抽出,コドフォのhtmlをよく見て該当部分の属性で抽出\n",
    "    problem_span = problem_parse.find_all(\"span\")\n",
    "    for elem in problem_span:\n",
    "        try:\n",
    "            elem_cls = elem.get(\"class\")[0]\n",
    "            if(elem_cls == \"tag-box\"):\n",
    "                res[\"tags\"].append(elem.string)\n",
    "        except:\n",
    "            pass\n",
    "    res[\"tags\"]=\"\".join(res[\"tags\"])\n",
    "    assert type(res[\"problem_text\"])==type(res[\"input_text\"])==type(res[\"output_text\"])==type(res[\"tags\"])==str, \"output is not strings\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://codeforces.com/problemset/problem/\"\n",
    "prob_nums = [str(i) for i in range(200,1500)] #200回から最新まで抽出\n",
    "capital = [chr(i) for i in range(65, 65+9)] #ABCDEFGHI\n",
    "prob_names = capital + [e+\"1\" for e in capital] #easyとhardがある場合があるがhardは割愛(問題文がほぼ同じため)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\"prob_id\":[],\"problem_texts\":[],\"input_texts\":[],\"output_texts\":[],\"tag_set\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_point=0\n",
    "for num in prob_nums:\n",
    "    for name in prob_names:\n",
    "        prob_id = num+\"/\"+name\n",
    "        try:\n",
    "            datum = extract_text_from_cf_problem_page(base_url+prob_id)\n",
    "            df[\"prob_id\"].append(prob_id)\n",
    "            df[\"problem_texts\"].append(datum[\"problem_text\"])\n",
    "            df[\"input_texts\"].append(datum[\"input_text\"])\n",
    "            df[\"output_texts\"].append(datum[\"output_text\"])\n",
    "            df[\"tag_set\"].append(datum[\"tags\"])\n",
    "        except:\n",
    "            pass\n",
    "        assert len(df[\"prob_id\"])==len(df[\"problem_texts\"])==len(df[\"input_texts\"])==len(df[\"output_texts\"])==len(df[\"tag_set\"]), \"does not the same length\"\n",
    "    if(save_point%10==0):\n",
    "        pd.DataFrame(df).to_csv(\"../data/cf_problem_tag_dataset.csv\",index=False)\n",
    "        save_point+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"../data/cf_problem_tag_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}